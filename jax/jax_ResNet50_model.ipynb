{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jax-ResNet50 model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2iylSxzRK0Ms8ytdB+DTW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiangShuLing/TensorFlowLearning/blob/main/jax/jax_ResNet50_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB6xEyiBzyrf"
      },
      "source": [
        "import numpy.random as npr\r\n",
        "import jax.numpy as jnp\r\n",
        "from jax import jit,grad,random\r\n",
        "from jax.experimental import optimizers\r\n",
        "from jax.experimental import stax\r\n",
        "from jax.experimental.stax import AvgPool,BatchNorm,Dense,FanInSum,FanOut,Flatten, GeneralConv,Identity,MaxPool,Relu,LogSoftmax"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFVZ4-8Jeh62"
      },
      "source": [
        "jax.experimental.stax里面包含很多函数，大部分都是定义网络的函数，比如Dense,GeneralConv, Conv--实现了GeneralConv;\r\n",
        "GeneralConvTranspose, \r\n",
        "\r\n",
        "池化： AvgPool, MaxPool\r\n",
        "\r\n",
        "BatchNorm层：参数标准化\r\n",
        "\r\n",
        "FanOut(b): fan-out layer,对输入进行泛化处理，整体乘以参数b\r\n",
        "\r\n",
        "FanInSum(): FanIn sum层，对输入进行求和处理\r\n",
        "\r\n",
        "函数：实现了jax.nn里面的函数\r\n",
        "Tanh，Relu，Exp，LogSoftmax，Softmax，Softplus，Sigmoid ，Elu，LeakyRelu，Selu，Gelu\r\n",
        "\r\n",
        "shape_dependent(make_layer): \r\n",
        "  \"\"\"Combinator to delay layer constructor pair until input shapes are known."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z7aR4jx0p6W"
      },
      "source": [
        "#通过Conv层实现ConvBlock\r\n",
        "def ConvBlock(kernel_size,filters,strides=(2,2)):\r\n",
        "  ks=kernel_size\r\n",
        "  filter1,filter2,filter3=filters\r\n",
        "\r\n",
        "  Main=stax.serial(\r\n",
        "      Conv(filter1,(1,1),strides),BatchNorm(),Relu,\r\n",
        "      Conv(filter2,(ks,ks),padding='SAME'),BatchNorm(),Relu,\r\n",
        "      Conv(filter3,(1,1)),BatchNorm())\r\n",
        "  #定义网络结构，类似于keras的Sequential容器,下面再定义一个网络结构\r\n",
        "  Shortcut=stax.serial(Conv(filter3,(1,1),strides),BatchNorm())\r\n",
        "  return stax.serial(FanOut(2),stax.parallel(Main,Shortcut),FanInsum,Relu)  #再次拼接模型并返回\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UbS0OwDtCUY"
      },
      "source": [
        "def IdentityBlock(kernel_size,filters):\r\n",
        "  ks=kernel_size\r\n",
        "  filter1,filter2=filters\r\n",
        "  def make_main(input_shape):\r\n",
        "    return stax.serial(\r\n",
        "        Conv(filter1,(1,1)),BatchNorm(),Relu,\r\n",
        "        Conv(filter2,(ks,ks),padding='SAME'),BatchNorm(),Relu,\r\n",
        "        Conv(input_shape[3],(1,1)),BatchNorm())\r\n",
        "    \r\n",
        "    Main=stax.shape_dependent(make_main)   #等到输入确定后再工作的延迟层\r\n",
        "    return stax.serial(FanOut(2),stax.parallel(Main,Identity),FanInSum,Relu)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r1UTWSA4Z5_"
      },
      "source": [
        " #num_classes定义输出层多少类\r\n",
        "def ResNet50(num_classes): \r\n",
        "  return stax.serial(\r\n",
        "      GeneralConv(('HWCN','OIHW','NHWC'),64,(7,7),(2,2),'SAME'),\r\n",
        "      BatchNorm(),Relu,MaxPool((3,3),strides=(2,2)),\r\n",
        "      ConvBlock(3,[64,64,256],strides=(1,1)),\r\n",
        "      IdentityBlock(3, [64, 64]),\r\n",
        "      IdentityBlock(3, [64, 64]),\r\n",
        "      ConvBlock(3, [128, 128, 512]),\r\n",
        "      IdentityBlock(3, [128, 128]),\r\n",
        "      IdentityBlock(3, [128, 128]),\r\n",
        "      IdentityBlock(3, [128, 128]),\r\n",
        "      ConvBlock(3, [256, 256, 1024]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      ConvBlock(3, [512, 512, 2048]),\r\n",
        "      IdentityBlock(3, [512, 512]),\r\n",
        "      IdentityBlock(3, [512, 512]),\r\n",
        "      AvgPool((7, 7)), Flatten, Dense(num_classes), LogSoftmax\r\n",
        "  ) \r\n",
        "\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "0qgNiSrt5JS5",
        "outputId": "5416b1a5-f534-493e-bb3b-2ad77a13b262"
      },
      "source": [
        "def main_function():\r\n",
        "  rng_key=random.PRNGKey(0)\r\n",
        "  batch_size=8\r\n",
        "  num_classes=1001\r\n",
        "  input_shape=(224,224,3,batch_size)   #batch_size也定义了input_shape里面，同时后面synth_batches函数也使用了batch_size\r\n",
        "  step_size=0.1\r\n",
        "  num_steps=10\r\n",
        "\r\n",
        "#batch-->输入的train_db\r\n",
        "  def loss(params,batch):\r\n",
        "    inputs,targets=batch\r\n",
        "    logits=predict_fun(params,inputs)    #前向计算\r\n",
        "    return -jnp.sum(logits*targets)      #计算target与预测值logits的不同\r\n",
        "\r\n",
        "  def accuracy(params,batch):\r\n",
        "    inputs,targets=batch\r\n",
        "    target_class=jnp.argmax(target,axis=1)  #取最大值的索引，也就是预测的class类型\r\n",
        "    predicted_class=jnp.argmax(predict_fun(params,inputs),axis=-1)\r\n",
        "    return jnp.mean(predicted_class==target_class)  #如果类型相同就返回1否则0，返回求取平均值就是预测精度\r\n",
        "\r\n",
        "  def synth_batches():\r\n",
        "    rng=npr.RandomState(0)\r\n",
        "    while True:\r\n",
        "      images=rng.rand(*input_shape).astype('float32')     #通过随机数生成一张图片，实际上是通过导入获取的输入\r\n",
        "      labels=rng.randint(num_classes,size=(batch_size,1)) #labels取0-1000的随机数[1,3,5,....34]; shape=[batchsize,1],这是一个二维数组\r\n",
        "      onehot_labels=labels==jnp.arange(num_classes)       #num_classess定义了某一类，比如1001，jnp.arange(1001)=[0,1,....,1001]，#与上面的二维数组对比可以返回batch_size个行，num_classess个列，对应相同数字为true，其他为false,  见下面的例子\r\n",
        "      yield images, oneHot_label\r\n",
        "\r\n",
        "      #简单地讲，yield 的作用就是把一个函数变成一个 generator，带有 yield 的函数不再是一个普通函数，Python 解释器会将其视为一个 generator，\r\n",
        "      # 调用函数不会执行简单执行函数，而是返回一个 iterable 对象\r\n",
        "\r\n",
        "\r\n",
        "#定义反向传播计算，opt_state储存了params\r\n",
        "  @jit\r\n",
        "  def update(i, opt_state,batch):\r\n",
        "    params=get_params(opt_state)      \r\n",
        "    return opt_update(i,grad(loss)(params,batchs),opt_state)\r\n",
        "\r\n",
        "\r\n",
        "  opt_init,opt_update,get_params=optimizers.momentum(step_size,mass=0.9)  #实例化优化器,返回参数初始化，更新函数，以及获取参数函数\r\n",
        "  batches=synth_batches()         #获取input以及label，如果有自己的数据需要手动修改synth_batch函数\r\n",
        "\r\n",
        "  init_fun,predic_fun=ResNet50(num_classes)   #初始化参数模型与网络模型\r\n",
        "  _,init_params=init_fun(rng_key,input_shape) #通过随机key与shape初始化参数\r\n",
        "\r\n",
        "  opt_state=opt_init(init_params)             #传入初始化参数，再次用优化器初始化方法再次初始化一次\r\n",
        "  for i in range(num_steps):                  #训练\r\n",
        "    opt_state=update(i,opt_state,next(batches))\r\n",
        "  \r\n",
        "  trained_params=get_params(opt_state)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "                           \r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-0ec84c28691b>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKcVPZMhoHIf",
        "outputId": "706f891e-cb3b-4cfe-9c57-0561a649b3d8"
      },
      "source": [
        "import jax.numpy as jnp\r\n",
        "import numpy as np\r\n",
        "def func():\r\n",
        "  a=np.random.randint(10,size=(5,1))\r\n",
        "  b=jnp.arange(10)\r\n",
        "  oneHot_label=a==b\r\n",
        "  return oneHot_label\r\n",
        "input_shape=[6,6,3]\r\n",
        "batch=np.random.rand(*input_shape).astype('float32')\r\n",
        "print(func())\r\n",
        "print(batch)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False False False False False False False False  True False]\n",
            " [False False False False  True False False False False False]\n",
            " [False False False False False False False False  True False]\n",
            " [False False False False False False False False  True False]\n",
            " [False  True False False False False False False False False]]\n",
            "[[[0.996387   0.87808317 0.8637553 ]\n",
            "  [0.21135399 0.9317122  0.46110785]\n",
            "  [0.1203807  0.6731061  0.5242455 ]\n",
            "  [0.6146163  0.32530114 0.02769888]\n",
            "  [0.2761006  0.05915179 0.06862331]\n",
            "  [0.14095677 0.52993107 0.22641619]]\n",
            "\n",
            " [[0.9442227  0.6381997  0.3695001 ]\n",
            "  [0.9416853  0.5664792  0.6032861 ]\n",
            "  [0.7807215  0.06147199 0.3829453 ]\n",
            "  [0.6002664  0.18294187 0.62751067]\n",
            "  [0.43741965 0.4259239  0.19758964]\n",
            "  [0.2659596  0.6253737  0.9951261 ]]\n",
            "\n",
            " [[0.8369199  0.22072919 0.07965129]\n",
            "  [0.9641116  0.38260308 0.29199386]\n",
            "  [0.94261    0.14893198 0.11456693]\n",
            "  [0.68703055 0.27786544 0.5604089 ]\n",
            "  [0.5024627  0.59090036 0.04744342]\n",
            "  [0.88360524 0.94454193 0.41223547]]\n",
            "\n",
            " [[0.4826714  0.8169855  0.4660373 ]\n",
            "  [0.6528622  0.6319818  0.3812876 ]\n",
            "  [0.8054012  0.73584694 0.05234069]\n",
            "  [0.54276824 0.06660881 0.46043774]\n",
            "  [0.62871194 0.93931246 0.6281381 ]\n",
            "  [0.13244885 0.53347355 0.9633522 ]]\n",
            "\n",
            " [[0.2823397  0.0766243  0.27412087]\n",
            "  [0.3224698  0.8232754  0.4764837 ]\n",
            "  [0.9259807  0.3864931  0.696715  ]\n",
            "  [0.10429534 0.5588977  0.70096606]\n",
            "  [0.10699034 0.06670088 0.06520516]\n",
            "  [0.03768411 0.10452539 0.9717901 ]]\n",
            "\n",
            " [[0.5037006  0.05078131 0.4655102 ]\n",
            "  [0.4215974  0.60822326 0.19029413]\n",
            "  [0.55789137 0.65300554 0.66283697]\n",
            "  [0.04552111 0.2917797  0.81808996]\n",
            "  [0.29268318 0.9634371  0.5833377 ]\n",
            "  [0.8374321  0.74707603 0.7017164 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WDNMK-boJzZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}