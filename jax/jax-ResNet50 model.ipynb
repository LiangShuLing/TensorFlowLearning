{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOP8vS1rZz5RxIrwMPrptmo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiangShuLing/TensorFlowLearning/blob/main/jax/jax-ResNet50%20model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB6xEyiBzyrf"
      },
      "source": [
        "import numpy.random as npr\r\n",
        "import jax.numpy as jnp\r\n",
        "from jax.experimental import optimizers\r\n",
        "from jax.experimental import stax\r\n",
        "from jax.experimental.stax import AvgPool,BatchNorm,Dense,FanInSum,FanOut,Flatten, GeneralConv,Identity,MaxPool,Relu,LogSoftmax"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFVZ4-8Jeh62"
      },
      "source": [
        "jax.experimental.stax里面包含很多函数，大部分都是定义网络的函数，比如Dense,GeneralConv, Conv--实现了GeneralConv;\r\n",
        "GeneralConvTranspose, \r\n",
        "\r\n",
        "池化： AvgPool, MaxPool\r\n",
        "\r\n",
        "BatchNorm层：参数标准化\r\n",
        "\r\n",
        "FanOut(b): fan-out layer,对输入进行泛化处理，整体乘以参数b\r\n",
        "\r\n",
        "FanInSum(): FanIn sum层，对输入进行求和处理\r\n",
        "\r\n",
        "函数：实现了jax.nn里面的函数\r\n",
        "Tanh，Relu，Exp，LogSoftmax，Softmax，Softplus，Sigmoid ，Elu，LeakyRelu，Selu，Gelu\r\n",
        "\r\n",
        "shape_dependent(make_layer): \r\n",
        "  \"\"\"Combinator to delay layer constructor pair until input shapes are known."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z7aR4jx0p6W"
      },
      "source": [
        "#通过Conv层实现ConvBlock\r\n",
        "def ConvBlock(kernel_size,filters,strides=(2,2)):\r\n",
        "  ks=kernel_size\r\n",
        "  filter1,filter2,filter3=filters\r\n",
        "\r\n",
        "  Main=stax.serial(\r\n",
        "      Conv(filter1,(1,1),strides),BatchNorm(),Relu,\r\n",
        "      Conv(filter2,(ks,ks),padding='SAME'),BatchNorm(),Relu,\r\n",
        "      Conv(filter3,(1,1)),BatchNorm())\r\n",
        "  #定义网络结构，类似于keras的Sequential容器,下面再定义一个网络结构\r\n",
        "  Shortcut=stax.serial(Conv(filter3,(1,1),strides),BatchNorm())\r\n",
        "  return stax.serial(FanOut(2),stax.parallel(Main,Shortcut),FanInsum,Relu)  #再次拼接模型并返回\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UbS0OwDtCUY"
      },
      "source": [
        "def IdentityBlock(kernel_size,filters):\r\n",
        "  ks=kernel_size\r\n",
        "  filter1,filter2=filters\r\n",
        "  def make_main(input_shape):\r\n",
        "    return stax.serial(\r\n",
        "        Conv(filter1,(1,1)),BatchNorm(),Relu,\r\n",
        "        Conv(filter2,(ks,ks),padding='SAME'),BatchNorm(),Relu,\r\n",
        "        Conv(input_shape[3],(1,1)),BatchNorm())\r\n",
        "    \r\n",
        "    Main=stax.shape_dependent(make_main)   #等到输入确定后再工作的延迟层\r\n",
        "    return stax.serial(FanOut(2),stax.parallel(Main,Identity),FanInSum,Relu)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r1UTWSA4Z5_"
      },
      "source": [
        " #num_classes定义输出层多少类\r\n",
        "def ResNet50(num_classes): \r\n",
        "  return stax.serial(\r\n",
        "      GeneralConv(('HWCN','OIHW','NHWC'),64,(7,7),(2,2),'SAME'),\r\n",
        "      BatchNorm(),Relu,MaxPool((3,3),strides=(2,2)),\r\n",
        "      ConvBlock(3,[64,64,256],strides=(1,1)),\r\n",
        "      IdentityBlock(3, [64, 64]),\r\n",
        "      IdentityBlock(3, [64, 64]),\r\n",
        "      ConvBlock(3, [128, 128, 512]),\r\n",
        "      IdentityBlock(3, [128, 128]),\r\n",
        "      IdentityBlock(3, [128, 128]),\r\n",
        "      IdentityBlock(3, [128, 128]),\r\n",
        "      ConvBlock(3, [256, 256, 1024]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      IdentityBlock(3, [256, 256]),\r\n",
        "      ConvBlock(3, [512, 512, 2048]),\r\n",
        "      IdentityBlock(3, [512, 512]),\r\n",
        "      IdentityBlock(3, [512, 512]),\r\n",
        "      AvgPool((7, 7)), Flatten, Dense(num_classes), LogSoftmax\r\n",
        "  ) \r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qgNiSrt5JS5"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}