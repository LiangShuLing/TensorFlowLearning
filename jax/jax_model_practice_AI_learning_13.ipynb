{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jax model practice- AI learning 13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuPu2gZCrsIDBxBBdinJMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiangShuLing/TensorFlowLearning/blob/main/jax/jax_model_practice_AI_learning_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nznMp4M_iTP"
      },
      "source": [
        "import time\r\n",
        "import itertools\r\n",
        "import numpy as np\r\n",
        "import numpy.random as jnp\r\n",
        "from jax import jit, grad, random\r\n",
        "from jax.experimental import optimizers, stax\r\n",
        "from jax.experimental.stax import Dense, Relu, LogSoftmax\r\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTdfkxUF1j_3"
      },
      "source": [
        "# define the loss function\r\n",
        "def loss(params, batch):\r\n",
        "  inputs, targets=batch\r\n",
        "  logits=predict(params,inputs)\r\n",
        "  return -jnp.mean(jnp.sum(logits*targets,axis=1))\r\n",
        "\r\n",
        "def accuracy(params,batch):\r\n",
        "  inputs,targets=batch\r\n",
        "  target_class=jnp.argmax(targets,axis=1)\r\n",
        "  predicted_class=jnp.argmax(predict(params,inputs),axis=1)\r\n",
        "  return jnp.mean(predicted_class==target_class)\r\n",
        "\r\n",
        "# define the network model\r\n",
        "init_random_params, preict=stax.serial(\r\n",
        "    Dense(25),Relu,\r\n",
        "    Dense(12),Relu,\r\n",
        "    Dense(6),LogSoftmax)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koFqwtWM3Hhv"
      },
      "source": [
        "def main_func():\r\n",
        "  rng=random.PRNGKey(0)\r\n",
        "\r\n",
        "  step_size=0.001\r\n",
        "  num_epochs=10\r\n",
        "  batch_size=128\r\n",
        "  momentum_mass=0.9\r\n",
        "\r\n",
        "#load data\r\n",
        "  train_images, train_labels, test_images, test_labels = datasets\r\n",
        "  num_train=train_images.shape[0]\r\n",
        "  input_shape=(train_images[0].shape, batch_size)\r\n",
        "  \r\n",
        "  num_complete_batches, leftover=divmod(num_train,batch_size)  # python divmod() 函数把除数和余数运算结果结合起来，返回一个包含商和余数的元组(a // b, a % b)。\r\n",
        "  #返回完整的batch个数，以及剩下的train data\r\n",
        "  num_batches=num_complete_batches+bool(leftover)   #如果还有剩下data, batch数加一，否则加0\r\n",
        "\r\n",
        "  def data_stream():\r\n",
        "    rng=npr.RandomState(0)\r\n",
        "\r\n",
        "    while True:\r\n",
        "      perm=rng.permutation(num_train)  # 随机排列一个序列，或者数组。如果x是多维数组，则沿其第一个坐标轴的索引随机排列数组。\r\n",
        "      for i in range(num_batches):\r\n",
        "        batch_idx=perm[i*batch_size:(i+1)*batch_size]   #按batch_size来取数据的索引\r\n",
        "        yield train_images[batch_idx],train_labels[batch_idx]  #按照索引来获取训练数据与标签\r\n",
        "\r\n",
        "  batches=data_stream()\r\n",
        "\r\n",
        "  opt_init,opt_update, get_params=optimizers.adam(step_size,eps=0.0001)  #使用Adam优化器\r\n",
        "\r\n",
        "  @jit\r\n",
        "  def update(i,opt_state,batch):\r\n",
        "    params=get_params(opt_state)\r\n",
        "    return opt_update(i,grad(loss)(params,batch),opt_state)\r\n",
        "  \r\n",
        "  _, init_params=init_random_params(rng,input_shape)\r\n",
        "  opt_state=opt_init(init_params)\r\n",
        "  itercount=itertools.count()\r\n",
        "\r\n",
        "  print('\\nStarting training...')\r\n",
        "  for epoch in range(num_epoches):\r\n",
        "    start_time=time.time()\r\n",
        "\r\n",
        "    for _ in range(num_batches):\r\n",
        "      opt_state=update(next(itercount),opt_state,next(batches))\r\n",
        "    epoch_time=time.time()-start_time\r\n",
        "\r\n",
        "    params=get_params(opt_state)\r\n",
        "    train_acc=accuracy(params,(train_images,train_labels))\r\n",
        "    test_acc=accuracy(params,(test_images,test_labels))\r\n",
        "    print(\"Epoch {} in {:0.2f} sec\".format(epoch,epoch_time))\r\n",
        "    print(\"Training set accuracy {}\".format(train_acc))\r\n",
        "    print(\"Test set accuracy {}\".format(test_acc))\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}